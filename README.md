# Accelerating CNN Hyperparameter Tuning with TPE and Statistical Early Stopping

Hyperparameter optimization (HPO) plays a crucial role in training high-performing deep learning models, but existing methods such as Random Search, Hyperband, and Tree-structured Parzen Estimators (TPE) often rely on predefined iteration budgets, leading to inefficient use of computational resources if suboptimal configurations are continuously evaluated after an optimal hyperparameter configuration is evident. This project presents Auto-TPE, an automatic termination method for training convolutional neural networks (CNNs) using TPE. Auto-TPE dynamically terminates the HPO process once the potential for a better hyperparameter configuration is statistically unlikely.
